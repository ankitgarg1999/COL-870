# -*- coding: utf-8 -*-
"""run_generator.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QW2ON9rpJUPIt3hoABUZrwfbW1CAWEmS
"""

import sys 


path_train  = str(sys.argv[1])
path_sample = str(sys.argv[2])
out_images  = str(sys.argv[3])
out_labels  = str(sys.argv[4])

import   numpy as np
from     sklearn.cluster import KMeans
import   matplotlib.pyplot as plt
from     PIL import Image
import   cv2
import   torch
import   torch.nn as nn
import   torch.nn.functional as F
import   torch.optim as optim
from     torch.utils.data.sampler import SubsetRandomSampler
from     torch.utils.data import DataLoader, TensorDataset, Dataset
from     torchvision import datasets, transforms
from     sklearn.neighbors import KNeighborsClassifier
import   copy 
import   imageio

class augment(Dataset):

    def __init__(self, data, transform):
        self.data = data
        self.transform = transform

    def __len__(self):
        return len(self.data.shape[0])

    def __getitem__(self, idx):
        item = self.data[idx]
        item = self.transform(item)
        return item

transform = transforms.Compose([
        transforms.ToPILImage(),
        transforms.RandomAffine(40, translate=(0,.25), scale=(1,1.2), shear=None,  fill=255)
        ,transforms.ToTensor()
    ])

labelled_images = np.load(path_sample)/255

temp = torch.tensor(labelled_images[1:9,:,:])

for i in range(5):
  augmented_labels= augment(torch.tensor(labelled_images[1:9,:,:]), transform)
  temp = torch.cat((temp, augmented_labels.data), 0)

labelled_images = temp


# Load Query Images 

digit_collection = []

for i in range(10000): 
  img = Image.open( path_train + '/query/'+ str(i)+'.png')
  img = np.asarray(img)  
  h_tiles = np.hsplit(img, 8)
  for tile in h_tiles:
    digit_collection = digit_collection + np.vsplit(tile, 8)
X_train = (np.stack(digit_collection))/255.0 #Normalise
X_train = X_train.astype(np.int8)
np.save("./query", X_train)

# Load Target Labels
digit_collection = []

for i in range(10000): 
  img = Image.open( path_train + '/target/'+ str(i)+'.png')
  img = np.asarray(img) 
  h_tiles = np.hsplit(img, 8)
  for tile in h_tiles:
    digit_collection = digit_collection + np.vsplit(tile, 8)
X_train = (np.stack(digit_collection))/255.0 #Normalise
# X_train = X_train.astype(np.int8)
np.save("./target", X_train.astype(np.int8))


## Create Loaders 

b_size = 512
X = np.reshape(X_train, (-1, 1, 28, 28))
X_t = torch.Tensor(X)

X_train_t = X_t[:512000,:,:,:]
train_data   = TensorDataset(X_train_t) # create your datset
train_loader = DataLoader(train_data, 
                          batch_size=b_size, 
                          shuffle=True)
X_val_t = X_t[512000:,:,:,:]
val_data   = TensorDataset(X_val_t) # create your datset
val_loader = DataLoader(val_data, 
                          batch_size=b_size, 
                          shuffle=False)


# Auto Encoder 

class convAE(nn.Module):
    def __init__(self):

        super(convAE, self).__init__()

        self.conv1 = nn.Conv2d(1, 16, 3, stride=2, padding=1)
        self.d1 = nn.Dropout2d()
        self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)
        self.d2 = nn.Dropout2d()
        self.conv3 = nn.Conv2d(32, 64, 7)

        self.deconv1 = nn.ConvTranspose2d(64, 32, 7)
        self.d3 = nn.Dropout2d()
        self.deconv2 = nn.ConvTranspose2d(32, 16, 3, stride=2, padding=1, output_padding=1)
        self.d4 = nn.Dropout2d()
        self.deconv3 = nn.ConvTranspose2d(16, 1, 3, stride=2, padding=1, output_padding=1)

    def forward(self, x):
       
        x = F.relu(self.d1(self.conv1(x)))
        x = F.relu(self.d2(self.conv2(x)))
        x = self.conv3(x)

        y = F.relu(self.d3(self.deconv1(x)))
        y = F.relu(self.d4(self.deconv2(y)))
        y = torch.sigmoid(self.deconv3(y))
        return y, x

def loss_fn(output, target):
  logx1 = torch.log(output + 1e-8)
  logx0 = torch.log(1 - output + 1e-8)

  weight_sum = (logx1*target)*0.3 + (logx0*(1 - target))*0.7
  return torch.neg(torch.mean(weight_sum))

def loss_fn_2(z_labelled):
  # input [48, 64] 

  loss = 0

  cos = nn.CosineSimilarity(dim=0, eps=1e-6)

  count = 0

  for i in range(0,48):

    if (np.random.randint(0,4) != 0):
      continue

    for j in range(i+1,48):

      if (np.random.randint(0,4) != 0):
        continue

      if (i%8 == j%8):
        loss += (1 - cos(z_labelled[i], z_labelled[j]))

      else:
        loss += (1 + cos(z_labelled[i], z_labelled[j]))

      count += 1

  loss = loss / count

  return loss

##############################################
# Train the AE 
##############################################
n_epochs = 60
alpha = 0.5

neural_net = convAE()
neural_net = neural_net.cuda()

optm = optim.Adam(neural_net.parameters(), lr = 1e-2, weight_decay= 0.0001) 
min_loss = 100

lmbda = lambda epoch: 0.95
scheduler = torch.optim.lr_scheduler.MultiplicativeLR(optm, lr_lambda=lmbda)

for epoch in range(n_epochs):
  loss_t = 0 
  
  neural_net.train()
  for data in train_loader: 
    image = data[0].cuda()

    aug_image = augment(image, transform)
    image = torch.cat((image, aug_image.data), 0)

    optm.zero_grad()

    loss = nn.MSELoss()
    output, _ = neural_net.forward(image)
    _, output2 = neural_net.forward(labelled_images.reshape(-1,1,28,28).float().cuda())
    ll = loss_fn(output,image) + alpha*loss_fn_2(output2)
    ll.backward()
    optm.step()

    loss_t += (ll.item()*b_size)
    torch.cuda.empty_cache()

  loss_t = loss_t / (512000*2)
  scheduler.step()

  loss_v = 0
  neural_net.eval()
  with torch.no_grad():
    for val_data in val_loader:
      image = val_data[0].cuda()
    
      loss = nn.MSELoss()
      output, _ = neural_net.forward(image)
      ll = loss_fn(output,image)

      loss_v += (ll.item()*b_size)
      torch.cuda.empty_cache()
  
  loss_v = loss_v / (128000)

  if ((epoch+1)%1 == 0):
    print("Autoencoder: Epoch: " + str(epoch+1) + " Training Loss = "+str(loss_t) + " Val Loss = "+ str(loss_v))
  if (loss_v <= min_loss):
    min_loss = loss_v
    torch.save(neural_net, './autoencoder.pth')


####################################################
# Use Nearest Neighbour
###################################################
AE = convAE()
AE = torch.load('./autoencoder.pth')
AE = AE.cuda()
AE.eval()  

latent_data  = TensorDataset(X_t)
latent_loader = DataLoader(latent_data, 
                          batch_size=1000, 
                          shuffle=False)
Z = []
for data in latent_loader:
  with torch.no_grad():
    image = data[0].cuda()
    y, x = AE(image)
    x = x.cpu()
    Z.append(x)

Z = (torch.cat([torch.reshape(z,(-1, 64)) for z in Z])).numpy()

labelled_images_t = labelled_images[:,:,:].reshape(48, 1, 28, 28)
latent_images_data  = TensorDataset(labelled_images_t)
labelled_images_loader = DataLoader(latent_images_data, batch_size=5, shuffle=False)

Z_labelled_images = []
for data in labelled_images_loader:
  with torch.no_grad():
    image = data[0].cuda().float()
    y, x = AE(image)
    x = x.cpu()
    Z_labelled_images.append(x)

Z_labelled_images = (torch.cat([torch.reshape(z,(-1, 64)) for z in Z_labelled_images])).numpy()

neigh = KNeighborsClassifier(n_neighbors=1)
neigh.fit(Z_labelled_images[:8,:], np.array([1,2,3,4,5,6,7,8]))
labels = neigh.predict(Z)

np.save("./t_labels", np.reshape(labels, (-1,1)))

X_query = np.load('./query.npy').astype(np.float64)
X_target = np.load('./target.npy').astype(np.float64)
labels = np.load("./t_labels.npy") 

print(X_query.shape, X_target.shape, labels.shape)

count = 0
for i in range(0, X_query.shape[0]):
  if ((X_query[i] == X_target[i]).all()):
    continue
  else:
    labels[i][0] = 0
    count += 1

np.save("./q_labels.npy", labels)




##########################################
##########################################
#   CGAN                   
##########################################

def plot_image(image):
  plt.imshow(image, cmap='gray', vmin=np.amin(image), vmax=np.amax(image))
  plt.show()

def one_hot_encode(labels):
  labels_one_hot = np.zeros((labels.shape[0],9), dtype=np.float32)
  for i in range(labels.shape[0]):
    labels_one_hot[i][labels[i][0]] = 0.9
  return labels_one_hot 

def convert_to_uint8(im):
  im = (((im - np.amin(im)) / (np.amax(im) - np.amin(im))) * 255).astype(np.uint8)
  return im

def plot_fake_images(G):

  y = [[0, 0, 0, 0, 0, 0, 0, 0, 0]]

  with torch.no_grad():
    fig, axs= plt.subplots(1, 8)     
    for i in range(0, 9):

      x = copy.deepcopy(y)
      x[0][i] = 1
      x = (torch.tensor(x).float()).cuda()
      z = (torch.randn(1, 100).cuda()).float()

      output = G(z,x)
      im = ((output[0].reshape(28,28)).cpu()).detach().numpy()
      axs[i-1].imshow(im, cmap='gray', vmin=np.amin(im), vmax=np.amax(im))
    plt.show()


class MyDataset (Dataset):

  def __init__(self, X, Y):
    self.X = X
    self.Y = Y

  def __len__(self):
    return (self.X).shape[0]

  def __getitem__(self, idx):
    return torch.from_numpy(self.X[idx]), torch.from_numpy(self.Y[idx])

X = np.load('./query.npy')
X = X.astype(np.float64)
Y = one_hot_encode(np.load('./q_labels.npy'))

# X = np.reshape(X, (640, -1))
X = np.reshape(X, (-1,784))

b_size = 128
train_dataset = MyDataset(X[:512000,:],Y[:512000,:])
val_dataset = MyDataset(X[512000:,:],Y[512000:,:])
train_loader = DataLoader(train_dataset, batch_size = b_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size = b_size, shuffle=False)
    
class generator(nn.Module):

  def __init__(self):

    super(generator, self).__init__()

    self.linear1_z = nn.Linear(100, 200)
    self.linear1_y = nn.Linear(9,1000)

    self.dropZ = nn.Dropout()
    self.dropY = nn.Dropout()

    self.linear2_comb = nn.Linear(1200,1200)
    self.dropZY = nn.Dropout()

    self.linear3 = nn.Linear(1200,784)

  def forward(self, z, y):

    z = F.leaky_relu( self.dropZ(self.linear1_z(z)), negative_slope=0.2)
    y = F.leaky_relu( self.dropY(self.linear1_y(y)), negative_slope=0.2)

    zy = torch.cat((z, y), 1 )
    zy = F.leaky_relu(self.dropZY(self.linear2_comb(zy)), negative_slope=0.2)

    z = self.linear3(zy)
    z = torch.sigmoid(z)

    return z

class discriminator(nn.Module):

  def __init__(self):

    super(discriminator, self).__init__()

    self.linear1_1_x = nn.Linear(784,240)
    self.linear1_2_x = nn.Linear(784,240)
    self.linear1_3_x = nn.Linear(784,240)
    self.linear1_4_x = nn.Linear(784,240)
    self.linear1_5_x = nn.Linear(784,240)

    self.dropX = nn.Dropout()

    self.linear1_1_y = nn.Linear(9,50)
    self.linear1_2_y = nn.Linear(9,50)
    self.linear1_3_y = nn.Linear(9,50)
    self.linear1_4_y = nn.Linear(9,50)
    self.linear1_5_y = nn.Linear(9,50)

    self.dropY = nn.Dropout()

    self.linear2_1 = nn.Linear(290,240)
    self.linear2_2 = nn.Linear(290,240)
    self.linear2_3 = nn.Linear(290,240)
    self.linear2_4 = nn.Linear(290,240)

    self.dropXY = nn.Dropout()

    self.linear3 = nn.Linear(240, 1)

  def forward(self, x, y):

    x11 = self.linear1_1_x(x)
    x12 = self.linear1_2_x(x)
    x13 = self.linear1_3_x(x)
    x14 = self.linear1_4_x(x)
    x15 = self.linear1_5_x(x)
    x = torch.maximum(x11, torch.maximum(x12, torch.maximum(x13, torch.maximum(x14, x15))))
    x = self.dropX(x)
    x = F.relu(x)

    y11 = self.linear1_1_y(y)
    y12 = self.linear1_2_y(y)
    y13 = self.linear1_3_y(y)
    y14 = self.linear1_4_y(y)
    y15 = self.linear1_5_y(y)
    y = torch.maximum(y11, torch.maximum(y12, torch.maximum(y13, torch.maximum(y14, y15))))
    y = self.dropY(y)
    y = F.relu(y)

    xy = torch.cat((x,y), 1)

    x21 = self.linear2_1(xy)
    x22 = self.linear2_2(xy)
    x23 = self.linear2_3(xy)
    x24 = self.linear2_4(xy)

    x = torch.maximum(x21, torch.maximum(x22, torch.maximum(x23, x24)))
    x = self.dropXY(x)
    x = F.relu(x)
    y = x

    x = self.linear3(x)
    x = torch.sigmoid(x)
    return x, y

D = discriminator()
G = generator()
D = D.cuda()
G = G.cuda()

k = 1

# optm_D = optim.SGD(D.parameters(), lr = 2e-4, momentum = 0.5, weight_decay= 0.0001) 
# optm_G = optim.SGD(G.parameters(), lr = 1e-4, momentum = 0.5, weight_decay= 0.0001) 

optm_D = optim.RMSprop(D.parameters(), lr = 2e-4, momentum = 0.5, weight_decay= 0.0001) 
optm_G = optim.RMSprop(G.parameters(), lr = 1e-4, momentum = 0.5, weight_decay= 0.0001) 

lmbda = lambda epoch: (1/1.00004)
scheduler_d = optim.lr_scheduler.MultiplicativeLR(optm_D, lr_lambda=lmbda)
scheduler_g = optim.lr_scheduler.MultiplicativeLR(optm_G, lr_lambda=lmbda)

min_loss = 100

train_dis_loss = []
train_gen_loss = []
val_dis_loss = []
val_gen_loss = []

n_epochs = 100
feature_reg = 0.3

mode = True

for epoch in range(n_epochs):
  
  D.train()
  G.train()

  count = 0

  llg = 0 
  lld = 0 

  for data in train_loader: 

    count += 1

    x = (data[0].cuda()).float()
    z = (torch.randn(x.shape[0], 100).cuda()).float()
    y = (data[1].cuda()).float()

    optm_D.zero_grad()

    D_real, f_real = D(x, y)
    D_gen , f_gen  = D(G(z, y), y)

    # loss = -(torch.log(D_real + 1e-8) + torch.log(1 - D_gen+ 1e-8)).mean()

    if (mode == True):
      loss = -(torch.log(D_real + 1e-8)).mean()
      mode = False 
    else: 
      loss = -(torch.log(1 - D_gen+ 1e-8)).mean()
      mode = True 

    loss.backward()

    lld += (loss.item())*b_size

    optm_D.step()

    if (count == k):

      z = (torch.randn(x.shape[0], 100).cuda()).float()

      count = 0
      optm_G.zero_grad()

      D_real, f_real = D(x, y)
      D_gen , f_gen  = D(G(z, y), y)

      # loss = torch.log(1 - D_gen + 1e-8).mean() + feature_reg * (torch.linalg.norm(f_real - f_gen, dim=1).mean())
      loss = - torch.log(D_gen + 1e-8).mean() + feature_reg * (torch.linalg.norm(f_real - f_gen, dim=1).mean())

      loss.backward()
      llg += (loss.item())*b_size

      optm_G.step()

    torch.cuda.empty_cache()

  scheduler_d.step()
  scheduler_g.step()

  loss_d = lld / (512000)
  loss_g = llg / (512000/k)

  print("Training")
  print("Epoch : " + str(epoch+1) + " Disc Loss: "+ str(loss_d) + " Gen Loss: "+ str(loss_g))
  train_dis_loss.append(loss_d)
  train_gen_loss.append(loss_g)

  D.eval()
  G.eval()

  lld_val = 0
  llg_val = 0  

  if ((epoch+1)%1 == 0):

    torch.save(G, './generator.pth')
    torch.save(D, './discriminator.pth')
    for data in val_loader:

      with torch.no_grad():

        x = (data[0].cuda()).float()
        z = (torch.randn(x.shape[0], 100).cuda()).float()
        y = (data[1].cuda()).float()

        D_real, f_real = D(x, y)
        D_gen , f_gen  = D(G(z, y), y)

        dis_loss = -(torch.log(D_real + 1e-8) + torch.log(1 - D_gen+ 1e-8)).mean() 
        # gen_loss = torch.log(1 - D_gen + 1e-8).mean() + feature_reg * (torch.linalg.norm(f_real - f_gen, dim=1).mean())
        gen_loss = -torch.log(D_gen + 1e-8).mean() + feature_reg * (torch.linalg.norm(f_real - f_gen, dim=1).mean())
     
        lld_val += (dis_loss.item())*b_size
        llg_val += (gen_loss.item())*b_size

        

      torch.cuda.empty_cache()

    #plot_fake_images(G)

    loss_d_val = lld_val / (128000)
    loss_g_val = llg_val / (128000)

    
    # print("Validation")
    # print("Epoch : " + str(epoch+1) + " Disc Loss: "+ str(loss_d_val) + " Gen Loss: "+ str(loss_g_val))

    val_dis_loss.append(loss_d_val)
    val_gen_loss.append(loss_g_val)

G.eval()

y = [[0, 0, 0, 0, 0, 0, 0, 0, 0]]

generated_labelled_data = np.zeros((9000,784))
labels = np.zeros((9000,1))

with torch.no_grad():    
  for i in range(0, 9):
    for j in range(0, 1000):

      x = copy.deepcopy(y)
      x[0][i] = 1
      
      x = (torch.tensor(x).float()).cuda()
      z = (torch.randn(1, 100).cuda()).float()
      output = ((G(z,x)[0]).cpu()).detach().numpy()
      generated_labelled_data[i*1000 + j] = output
      labels[i*1000 + j] = i

np.save(out_images, generated_labelled_data)
np.save(out_labels, labels)

#####################################
# FID
#####################################

path1 = "./real/"
path2 = "./fake/"

y = [[0, 0, 0, 0, 0, 0, 0, 0, 0]]

for i in range(0, 9):

  x = copy.deepcopy(y)
  x[0][i] = 1

  x = (torch.tensor(x).float()).cuda()

  for j in range(0,1000):
    z = (torch.randn(1, 100).cuda()).float()
    output = G(z, x)
    im = convert_to_uint8(((output[0].reshape(28,28)).cpu()).detach().numpy())
    image_name = path2 + str(i*1000 + j) + ".png"
    imageio.imwrite(image_name, im)

count = [0, 0, 0, 0, 0, 0, 0, 0, 0]

temp = 0
Y_idx = np.load('./q_labels.npy')

for i in range(0, 40000):
  
  if (count[Y_idx[i][0]]<1000):
    count[Y_idx[i][0]] += 1
    image_name = path1 + str(temp) + ".png"
    imageio.imwrite(image_name, convert_to_uint8(X[i].reshape((28,28))))   
    temp += 1